{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "word boundary model using neural network.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQwvjHAz025V",
        "colab_type": "text"
      },
      "source": [
        "**IMPORT ALL THE LIBRARY**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYCsyc3qdOsc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.io.wavfile import read\n",
        "from scipy.signal import spectrogram\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import librosa"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJ6TdAxLQScF",
        "colab_type": "text"
      },
      "source": [
        "specify the directory paths\n",
        "\n",
        "**all csv file names shold be same as audio files**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ky7KxLWdOsn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datadir_cutout = 'Project/word Boundary/word cutout/' # set the path of the csv files of the audio samples\n",
        "datadir_waves =  'Project/word Boundary/all wave files/' # set the path of the wave files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g62-O9NgKhGJ",
        "colab_type": "text"
      },
      "source": [
        "CREATING TRAINING DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74ilAxGpdOsr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_data=[]\n",
        "train_x = []\n",
        "train_y = []\n",
        "for files in tqdm(os.listdir(datadir_cutout)):\n",
        "    try:\n",
        "        fs,audio = read(datadir_waves + files[:-3] +'wav') \n",
        "        n = len(audio)\n",
        "        l = (((n//(fs//2))+1)*(fs//2))\n",
        "        audio =np.append(audio,np.zeros((l-n)))\n",
        "        df = pd.read_csv(datadir_cutout+files)\n",
        "        time  = np.arange(0,len(audio)/fs,1/fs)\n",
        "        m = min(len(time),len(audio))\n",
        "        word = np.zeros((len(audio)))\n",
        "        frame_word=[]\n",
        "        frame_time=[]\n",
        "        for i in range(df.shape[0]):\n",
        "            data = list(df.loc[i])[0].split('\\t')\n",
        "            start , duration = float(data[1][2:]),float(data[2][2:])\n",
        "            end = start+duration\n",
        "            word[int(start*fs+220) :int(end*fs-330) ] = 1\n",
        "        word =np.append(word,np.zeros((l-n)))\n",
        "        word_f=110\n",
        "        for i in range(len(audio)//word_f):\n",
        "            data = word[int(i*word_f):int((i+1)*word_f)]\n",
        "            if sum(data==0)!=0:\n",
        "                frame_word.append(0)\n",
        "                frame_time.append((i*word_f)/fs)\n",
        "            else:\n",
        "                frame_word.append(1)\n",
        "                frame_time.append((i*word_f)/fs)\n",
        "\n",
        "        # adding -1 to word break-------------------------------------------\n",
        "        for i in range(len(frame_word)-1):\n",
        "          if frame_word[i+1]!=frame_word[i]:\n",
        "                frame_word[i]=-1\n",
        "        frame_word = np.array(frame_word)\n",
        "        add_1_to_word = np.append([False],np.array(frame_word==-1)[:-1])\n",
        "        frame_word[add_1_to_word] = -1\n",
        "        # adding -1 to word break-----------------------------------------------\n",
        "        amp=audio\n",
        "        window = 0.005 # in ms\n",
        "        S = librosa.feature.melspectrogram(y=audio.astype('float'), sr=fs, n_mels=2*128,fmax=8000,hop_length=int(fs*window),n_fft=1024)\n",
        "        X = np.flipud(librosa.power_to_db(S)) \n",
        "        frame= 100 # 200 mean 1 sec\n",
        "        s_frame = 100 # 200 mean 1 sec\n",
        "        for i in range((l//(fs//2))):\n",
        "            train_x.append(X[:,int(s_frame*i):int(s_frame*(i+1))])\n",
        "            train_y.append(frame_word[int(frame*i):int(frame*(i+1))])\n",
        "    except Exception as e:\n",
        "      print('pass', e)\n",
        "      break\n",
        "     \n",
        "np.save(datadir +'X',train_x)\n",
        "np.save(datadir +'y',train_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqtSQo4adOsw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x = np.load(datadir+'X.npy',allow_pickle = True)\n",
        "train_y = np.load(datadir+'y.npy',allow_pickle = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmrCLzIEdOs0",
        "colab_type": "code",
        "outputId": "ee3155e0-902b-4b6f-fb50-85f926ee1457",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input,Dense,Flatten,Dropout,Conv2D,BatchNormalization,Reshape,LSTM,MaxPooling2D,LeakyReLU\n",
        "from tensorflow.keras.models import Model,Sequential,load_model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpQV0QH0dOs5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(64,(3,3),padding='same',input_shape=(256,100,1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU())\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "model.add(Conv2D(32,(3,3),padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU())\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "model.add(Conv2D(16,(3,3),padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU())\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "model.add(Conv2D(8,(3,3),padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU())\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(4,(3,3),padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU())\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(512,activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(256,activation='relu'))\n",
        "model.add(Dense(100,activation='sigmoid'))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exnLvl3xdOs9",
        "colab_type": "code",
        "outputId": "8c6843f2-58a7-480f-dbd6-0fcd3987a7a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_9 (Conv2D)            (None, 256, 100, 64)      640       \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 256, 100, 64)      256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)    (None, 256, 100, 64)      0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 256, 100, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 256, 100, 32)      18464     \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 256, 100, 32)      128       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_10 (LeakyReLU)   (None, 256, 100, 32)      0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 256, 100, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 256, 100, 16)      4624      \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 256, 100, 16)      64        \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_11 (LeakyReLU)   (None, 256, 100, 16)      0         \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 256, 100, 16)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 256, 100, 8)       1160      \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 256, 100, 8)       32        \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_12 (LeakyReLU)   (None, 256, 100, 8)       0         \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 256, 100, 8)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 256, 100, 4)       292       \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 256, 100, 4)       16        \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_13 (LeakyReLU)   (None, 256, 100, 4)       0         \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 256, 100, 4)       0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 102400)            0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 512)               52429312  \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 100)               25700     \n",
            "=================================================================\n",
            "Total params: 52,612,016\n",
            "Trainable params: 52,611,768\n",
            "Non-trainable params: 248\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjdcMJhMdOtG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DdkiG0ndOtP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "X=[]\n",
        "y=[]\n",
        "training_data = list(zip(train_x,train_y))\n",
        "np.random.shuffle(training_data)\n",
        "for i in training_data:\n",
        "    r = len(i[1])\n",
        "    if r==100:\n",
        "            X.append(i[0])\n",
        "            y.append(i[1])\n",
        "X = np.array(X).reshape(-1,256,100,1)\n",
        "\n",
        "\n",
        "X = (X-np.mean(X))/np.std(X) # normalize the data\n",
        "y = np.array(y).reshape(-1,100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBulPd6CdOtT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_name = datadir+'word_boundary-ver-1.0.model' \n",
        "callback = ModelCheckpoint(model_name,monitor='val_loss', save_best_only=True ,mode='min')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIfk3ImYdOta",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(X,y,batch_size=1,epochs=10,validation_split=0.3,callbacks=[callback])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbueeIs3dOtv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pre_prosessing(audio,fs=22050):\n",
        "    slot=[]\n",
        "    n = len(audio)\n",
        "    l = (((n//(fs//2))+1)*(fs//2))\n",
        "    audio =np.append(audio,np.zeros((l-n)))\n",
        "    time  = np.arange(0,len(audio)/fs,1/fs)\n",
        "    m = min(len(time),len(audio))\n",
        "    window = 0.005\n",
        "    S = librosa.feature.melspectrogram(y=audio.astype('float'), sr=fs, n_mels=2*128,fmax=8000,hop_length=int(fs*window),n_fft=1024)\n",
        "    X = np.flipud(librosa.power_to_db(S))\n",
        "    s_frame = 100 \n",
        "    join_predictions=[]\n",
        "    for i in range((l//(fs//2))):\n",
        "          slot.append(X[:,int(s_frame*i):int(s_frame*(i+1))])\n",
        "    slot = np.array(slot).reshape(-1,256,100,1)\n",
        "    slot = (slot-np.mean(slot))/np.std(slot)\n",
        "    for i in range(slot.shape[0]):\n",
        "        join_predictions.append(model.predict(slot[i:i+1])[0])\n",
        "    join_predictions = np.array(join_predictions).reshape(1,-1)\n",
        "    return join_predictions[0]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUf1aT8jLmd8",
        "colab_type": "text"
      },
      "source": [
        "TEST THE MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFjwj6iTdOtr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#test\n",
        "file_name ='s10_f1_a1' #add the file name\n",
        "fs,audio = read(datadir_waves + file_name +'.wav') \n",
        "df = pd.read_csv(datadir_cutout+file_name+'.csv')\n",
        "time  = np.arange(0,len(audio)/fs,1/fs)\n",
        "m = min(len(time),len(audio))\n",
        "\n",
        "\n",
        "result = pre_prosessing(audio)\n",
        "pred_time = np.linspace(0,((len(result)//100)*(fs/2))/fs,(len(result)//100)*100)\n",
        "  \n",
        " \n",
        "fig = plt.figure(figsize=(17,7))\n",
        "ax = fig.add_subplot(111)\n",
        "ax.plot(time[:m],(audio/np.max(audio))[:m])          \n",
        "ax.plot(pred_time,np.array(result),label = 'predicted')\n",
        "\n",
        "ax.legend()\n",
        "\n",
        "\n",
        "  \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
